{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SummEval example\n",
    "\n",
    "In this notebook, we use one summarization example from the SummEval to demostrate how to use the PairS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summary candidates: 16\n"
     ]
    }
   ],
   "source": [
    "from utils import shuffle_lists, calculate_correlation, load_newsroom, load_summEval, calculate_uncertainty, load_sf_data, CompareResultObject, insert_index_to_anchors\n",
    "\n",
    "\n",
    "summ_eval_path = '../data/SummEval/model_annotations.aligned.paired.jsonl'\n",
    "input_doc, output_doc, scores_doc = load_summEval(summ_eval_path, flat_output=False)\n",
    "scores_doc = scores_doc['coherence']\n",
    "\n",
    "doc_id = 42\n",
    "input, output, scores = input_doc[doc_id], output_doc[doc_id], scores_doc[doc_id]\n",
    "print('Number of summary candidates:', len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PairS-greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinhong/anaconda3/envs/pairs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards: 100%|██████████| 4/4 [1:09:33<00:00, 1043.27s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = 'cuda'\n",
    "\n",
    "model = 'meta-llama/Meta-Llama-3-8B'\n",
    "model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)   # base_model\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set the meta-parameters\n",
    "params = {\n",
    "    'dataset': 'SummEval',\n",
    "    'engine': \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    'aspect': 'coherence',\n",
    "    'eval_method': 'pairwise comparison',\n",
    "    'confidence_beam': False,  # False for PairS-greedy search\n",
    "    # 'beam_size': 2000,\n",
    "    # 'prob_gap': 0.1,\n",
    "    'api_call': 0,\n",
    "    'with_input': True,\n",
    "    'compare_log': {},\n",
    "    'calibration': False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinhong/anaconda3/envs/pairs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "Processing:  58%|█████▊    | 37/64 [00:16<00:12,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from sorting import merge_sort_indices, merge_sort\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Set the progress bar\n",
    "if params['confidence_beam']:\n",
    "    params['progress_bar'] = tqdm(total=int(len(input)**2), desc='Processing')\n",
    "else:\n",
    "    params['progress_bar'] = tqdm(total=int(len(input) * np.log2(len(input))), desc='Processing')\n",
    "\n",
    "# Shuffle the input, output, and scores\n",
    "input, output, scores = shuffle_lists(input, output, scores)\n",
    "\n",
    "# Perform the PairS-greedy ranking\n",
    "# Please note: All prompts are saved in /scripts/prompts.py\n",
    "ranking_indices = merge_sort_indices(input, output, params)\n",
    "\n",
    "params['progress_bar'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation: 0.119\n",
      "Kendall tau: 0.104\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation\n",
    "spearman_corr, kendall_tau = calculate_correlation(np.array(scores)[ranking_indices], list(range(len(scores))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PairS-beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set the meta-parameters\n",
    "params = {\n",
    "    'dataset': 'SummEval',\n",
    "    'engine': \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    'aspect': 'coherence',\n",
    "    'eval_method': 'pairwise comparison',\n",
    "    'confidence_beam': True,  # True for PairS-beam search\n",
    "    'beam_size': 2000,\n",
    "    'api_call': 0,\n",
    "    'prob_gap': 0.1,\n",
    "    'with_input': True,\n",
    "    'compare_log': {},\n",
    "    'calibration': False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|██▌       | 64/256 [00:19<00:58,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from sorting import merge_sort_indices, merge_sort\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Set the progress bar\n",
    "if params['confidence_beam']:\n",
    "    params['progress_bar'] = tqdm(total=int(len(input)**2), desc='Processing')\n",
    "else:\n",
    "    params['progress_bar'] = tqdm(total=int(len(input) * np.log2(len(input))), desc='Processing')\n",
    "\n",
    "# Shuffle the input, output, and scores\n",
    "input, output, scores = shuffle_lists(input, output, scores)\n",
    "\n",
    "# Perform the PairS-beam ranking\n",
    "# Please note: All prompts are saved in /scripts/prompts.py\n",
    "ranking_indices = merge_sort_indices(input, output, params)\n",
    "\n",
    "params['progress_bar'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation: 0.326\n",
      "Kendall tau: 0.261\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation\n",
    "spearman_corr, kendall_tau = calculate_correlation(np.array(scores)[ranking_indices], list(range(len(scores))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pairs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
